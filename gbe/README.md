# Processing data for the Global Biobank Engine â€” a pipeline

This guide will explain the usage of the `gbe.sh` script in this folder. The purpose of this script is to conveniently process and conduct preliminary analyses (compatible with GBE) on a table of phenotype definitions as defined during a session (an example of which can be found [here](https://github.com/rivas-lab/ukbb-tools/blob/master/phenotyping/example_phenotyping_session.tsv)). This includes:

 - Processing phenotypes into PLINK-compatible specifications (`.phe` files)
 - Running GWAS on the set of directly genotyped variants in UK BioBank

In the future, this may be expanded to other analyses such as GWAS on imputed data, additional genotype models, GWAS under multiple populations, etc.

## Description and Implementation

This is a shell script, designed for use as a parallelized array job with `sbatch --array`. For those unfamiliar with the Slurm management system, [here](https://www.sherlock.stanford.edu/docs/user-guide/running-jobs/) is a description of how job submission works on Sherlock, and [here](https://slurm.schedmd.com/job_array.html) is some documentation on array jobs.

In short, the idea for this script is to iterate over each line in the input table, define the corresponding `.phe` file, then conduct analysis. 

In order to accomplish this, the script will do the following steps within each array instance:

 - Call [`tsv_to_phenos.py`](https://github.com/rivas-lab/ukbb-tools/blob/master/phenotyping/scripts/tsv_to_phenos.py) using the `--only-this-row` option
 - Call [`gwas.py`](https://github.com/rivas-lab/ukbb-tools/blob/master/gwas/gwas.py) with the `--run-array` and `--run-now` options. The remaining flags are set to defaults used with GBE (namely, running analyses only on White British unrelated individuals).
 
_Note:_ The `--run-now` option will immediately run a GWAS (on directly genotyped data) directly on whichever node you get from the array job (as opposed to submitting a separate batch job, with parameters specified as arguments to `gwas.py`). This means you'll have to ensure the job specification for `gbe.sh` has enough compute (memory, time, etc.) to run this computation on each phenotype. The default parameters (24GB memory, 1 day of computation time) should suffice for most phenotypes, but in the event that the job fails, you will have to resubmit with more resources.

## Usage

Prior to running this script, you will need to specify:
1. An input table (line 20) and corresponding arguments on lines 21-27. These lines should be filled in with the (zero-indexed) corresponding column indices of your input table. 
2. The output directory for summary statistics (line 17). The output directory for the `.phe` file generated by this script will be automatically populated as the directory in which the `.tsv` file is located. 

Then, you're ready to run your analysis. Run the following command:

`wc -l path_to_tsv_file`

to retrieve the number of lines in this file. Subtract by 1 (if it has a header), and then input that number (we will call this "num_lines") in the command below:

`sbatch --array=1-num_lines gbe.sh`
