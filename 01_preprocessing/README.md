# Preprocessing

## Downloading the data

The PI (in this case, Manny) has the sole privilege of being able to request and download new datasets. For information about how to apply for new data, please go [here]().

Once the data is downloaded, clone this directory to wherever you are working.

## Unpacking/decrypting the data

[The official documentation (Using UKB data)](http://biobank.ctsu.ox.ac.uk/showcase/docs/UsingUKBData.pdf) explains this procedure.

`ukb_unpack` converts the raw files from biobank (which are `.enc` files) into `.enc_ukb` files, which are the decrypted version. In order to unpack the data, you will need to do three things:

1) `cd` to the directory in which the `.enc` file is.
2) Note the absolute path to the `ukb_unpack` program in the cloned `preprocessing` directory, or the relative path from the directory containing the `.enc` file to the `ukb_unpack` program.
3) There should be an Application ID (most likely 24983 for us) and a Run ID associated with each application for new data. When the application is approved, Manny should get an email containing a password for the dataset. Note this password down.

Finally, run the following command:

`/path/to/ukb_unpack ukbXXXX.enc password`

Depending on the size and complexity of the dataset, you could be looking at a couple of minutes' runtime. A `.enc_ukb` file should pop up in the same directory you are currently in - `ls` to check.

## Converting the data

`ukbconv` converts the `.enc_ukb` files just generated by the `ukb_unpack` program into `.tab` and other formats. Run the following command from the same directory as before, replacing `ukbXXXX.enc_ukb` with the name of your `.enc_ukb` file:

`/path/to/ukbconv ukbXXXX.enc_ukb R`

When the command finishes running, you will see that a couple of files (most importantly, a `.tab` file) is generated in the directory. This file will be used in downstream analyses. *NOTE*: Depending on the size and complexity of the dataset and the machine you are running on (I personally recommend 32GB RAM, 4 CPUs (`sdev -p mrivas -t 7-0:00:00 -m 32g -n4`)), you could be looking at a couple of hours' runtime. Run these conversion commands in `screen` or `tmux` if possible so that they can run in the background.

## (Optional) Generating a `.tab.columns` file

In order to save a list of fields that the dataset contains, you will want to generate a `.tab.columns` file from the `.tab` file you just created. This will provide you an easy way to look at all the fields in the file, but is not strictly necessary for the pipeline. Run the following to generate it within your directory, replacing `ukbXXXX.tab` with the name of your `.tab` file:

`paste <(head -n1 ukbXXXXX.tab| tr "\t" "\n") <(head -n1 ukb1XXXXX.tab| tr "\t" "\n" | tr "." "\t" )`

## Defining phenotypes

With the `.tab.columns` file in tow, you're ready to start [defining phenotypes](https://github.com/rivas-lab/ukbb-tools/tree/master/phenotyping_sessions).
